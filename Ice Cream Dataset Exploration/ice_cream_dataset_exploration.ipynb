{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ice Cream Dataset Exploration\n",
    "_Author: Robert Dibble_\n",
    "\n",
    "_**Purpose**_\n",
    "\n",
    "Imagine that you have just joined a well funded Ice Cream start-up as their data scientist. Your task is to find a unique selling point and/or competitive advantage that will ensure their success.\n",
    "\n",
    "_**Steps**_\n",
    "\n",
    "Using the [Ice Cream Dataset](https://www.kaggle.com/datasets/tysonpo/ice-cream-dataset) on Kaggle:\n",
    "1. Perform EDA to understand the market/consumer\n",
    "1. Identify possible use cases\n",
    "1. Select a use case and develop POC\n",
    "1. Provide recommendation with justification\n",
    "\n",
    "_N.B. For this analysis the focus shall be the combined products dataset as this is the simplest of the combined sets_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datavizml import (\n",
    "    ExploratoryDataAnalysis,\n",
    ")  # home made EDA library available at https://github.com/dibble07/datavizml/\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from csv intro pandas\n",
    "products_raw = pd.read_csv(os.path.join(\"data\", \"combined\", \"products.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show size, dtype and nullness of data\n",
    "products_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display random sample of data\n",
    "products_raw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if Ben and Jerry's is the only brand to populate subhead\n",
    "products_raw[[\"brand\", \"subhead\"]].groupby(\"brand\").nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with no value - 'key' is just for joining to other datasets and 'subhead' is minimally populated\n",
    "products_raw.drop(columns=[\"key\", \"subhead\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean and split string list\n",
    "def process_string_list(x):\n",
    "\n",
    "    # remove brackets\n",
    "    brackets_regex = re.compile(\"[\\[({].*[\\])}]\")\n",
    "    x = re.sub(brackets_regex, \" \", x)\n",
    "\n",
    "    # remove 'contains' warning\n",
    "    contains_regex = re.compile(\"CONTAIN.*\")\n",
    "    x = re.sub(contains_regex, \" \", x)\n",
    "\n",
    "    # remove special characters\n",
    "    x = x.replace(\"â€ \", \" \").replace(\"/\", \" \").replace(\"\\\\\", \" \")\n",
    "\n",
    "    # replace and/or with comma\n",
    "    x = x.replace(\" AND \", \",\").replace(\" OR \", \",\")\n",
    "\n",
    "    # split with comma, full stop or colon as delimiter\n",
    "    x = x.replace(\".\", \",\").replace(\":\", \",\").split(\",\")\n",
    "\n",
    "    # drop white spaces\n",
    "    x = set([i.strip() for i in x if len(i.strip()) > 0])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ingredients to list from comma separated string\n",
    "products_raw[\"ingredients\"] = products_raw[\"ingredients\"].apply(process_string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all ingredients to check tokenisation\n",
    "set([val for sublist in products_raw[\"ingredients\"].to_list() for val in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorise ingredients\n",
    "\n",
    "# initialise and fit multilabel classifier\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(products_raw[\"ingredients\"])\n",
    "\n",
    "# save results to dataframe and drop list version\n",
    "products_raw[mlb.classes_] = mlb.transform(products_raw[\"ingredients\"]).astype(bool)\n",
    "products_raw.drop(columns=\"ingredients\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible use cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify ingredients that correlate with high custoemr ratings\n",
    "    - Use Shapley values to calculate the impact of an ingredient on a rating\n",
    "    - ~~Use the Apriori algorithm to identify frequent ingredient combinations~~ - frequent doesn't mean good or unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d203e968258da72cd4118352c26f273da2f4e5303f1bd70f028c0e2c03554780"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
