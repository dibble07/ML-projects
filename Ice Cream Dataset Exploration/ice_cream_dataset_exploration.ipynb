{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ice Cream Dataset Exploration\n",
    "_Author: Robert Dibble_\n",
    "\n",
    "_**Purpose**_\n",
    "\n",
    "Imagine that you have just joined a well funded Ice Cream start-up as their data scientist. Your task is to find a unique selling point and/or competitive advantage that will ensure their success.\n",
    "\n",
    "_**Steps**_\n",
    "\n",
    "Using the [Ice Cream Dataset](https://www.kaggle.com/datasets/tysonpo/ice-cream-dataset) on Kaggle:\n",
    "1. Perform EDA to understand the market/consumer\n",
    "1. Identify possible use cases\n",
    "1. Select a use case and develop POC\n",
    "1. Provide recommendation with justification\n",
    "\n",
    "_N.B. For this analysis the focus shall be the combined products dataset as this is the simplest of the combined sets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import shap\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from csv into pandas\n",
    "products_raw = pd.read_csv(os.path.join(\"data\", \"combined\", \"products.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show size, dtype and nullness of data\n",
    "products_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show range and skew of numerical features\n",
    "products_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display random sample of data\n",
    "products_raw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if Ben and Jerry's is the only brand to populate subhead\n",
    "products_raw[[\"brand\", \"subhead\"]].groupby(\"brand\").nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with no value - 'key' is just for joining to other datasets and 'subhead' is minimally populated\n",
    "products_raw.drop(columns=[\"key\", \"subhead\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a range of features:\n",
    "- The name of the brand\n",
    "- The name of the flavour\n",
    "- A description of the flavour\n",
    "- The ingredients list\n",
    "- The average rating of the flavour\n",
    "- The number of reviews use to create the average rating\n",
    "\n",
    "The majority of these features are text based but could provide information about what contributes towards a flavour with good rating. The assumption is that higher rated products will have higher sales and profits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify ingredients that correlate with high customer ratings\n",
    "    - Use Shapley values to calculate the impact of an ingredient on a rating\n",
    "1. Repeat the above analysis for other columns\n",
    "    - What words in the name or description lead to a good rating\n",
    "1. Repeat the above analysis for the reviews dataset\n",
    "    - Which descriptive characteristics lead to good reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected proof of concept\n",
    "Identify which ingredients correlate with high customer ratings. This would allow product teams to focus their attention on the most popular ingredients when designing flavours. The relationships identified will be a correlation, not causation. Therefore, it will not ensure that an ingredient will _cause_ increased ratings but this relationship could be identified using A/B experimentation and/or user testing.\n",
    "\n",
    "_**Steps**_\n",
    "1. Clean and tokenise ingredients list\n",
    "1. Select and train model on data\n",
    "1. Calculate Shapley values to identify the impact of the presence of an ingredient on the rating\n",
    "1. Analyse impact of ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and tokenise ingredients list\n",
    "Process the string of comma separated ingredients into a list of individual ingredients. Removing:\n",
    "- Secondary information in brackets\n",
    "- Allergen warnings\n",
    "- Special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean and split ingredients\n",
    "def process_ingredients_string(x):\n",
    "\n",
    "    # remove brackets\n",
    "    brackets_regex = re.compile(\"[\\[({].*[\\])}]\")\n",
    "    x = re.sub(brackets_regex, \" \", x)\n",
    "\n",
    "    # remove 'contains' warning\n",
    "    contains_regex = re.compile(\"CONTAIN.*\")\n",
    "    x = re.sub(contains_regex, \" \", x)\n",
    "\n",
    "    # remove special characters\n",
    "    x = x.replace(\"†\", \" \").replace(\"/\", \" \").replace(\"\\\\\", \" \")\n",
    "\n",
    "    # replace and/or with comma\n",
    "    x = x.replace(\" AND \", \",\").replace(\" OR \", \",\")\n",
    "\n",
    "    # split with comma, full stop or colon as delimiter\n",
    "    x = x.replace(\".\", \",\").replace(\":\", \",\").split(\",\")\n",
    "\n",
    "    # drop white spaces\n",
    "    x = set([i.strip() for i in x if len(i.strip()) > 0])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ingredients to list from comma separated string\n",
    "products_raw[\"ingredients\"] = products_raw[\"ingredients\"].apply(\n",
    "    process_ingredients_string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all ingredients to check tokenisation\n",
    "set([val for sublist in products_raw[\"ingredients\"].to_list() for val in sublist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most ingredients have been sufficiently split out. There is some additional processing that could be done to cover things like:\n",
    "- Differences in UK vs USA spelling\n",
    "- Should variants of an ingredient be grouped, e.g. 'ALMOND EXTRACT', 'ALMONDS', 'ALMONDS ROASTED IN VEGETABLE OIL'\n",
    "- Single vs multiple, e.g. 'ARTIFICIAL FLAVOR', 'ARTIFICIAL FLAVORS'\n",
    "- Word ending - 'ARTIFICIAL FLAVOR', 'ARTIFICIAL FLAVORING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorise ingredients\n",
    "\n",
    "# initialise and fit multilabel classifier\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(products_raw[\"ingredients\"])\n",
    "\n",
    "# save results to dataframe and drop list version\n",
    "ingredients = pd.DataFrame(\n",
    "    mlb.transform(products_raw[\"ingredients\"]).astype(bool),\n",
    "    columns=mlb.classes_,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and train model on data\n",
    "The purpose of this model is to reflect the data as closely as possible. Therefore, the regression model was selected to be a KNN model as this is a minimally parametrised model architecture. A KNN model would normally require the features to be scaled - due to the distance based nature of the model - but as the features are all boolean, this is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise and fit KNN regressor\n",
    "knn = KNeighborsRegressor(n_neighbors=1, algorithm=\"brute\")\n",
    "knn.fit(ingredients.values, products_raw[\"rating\"])\n",
    "feature_names = ingredients.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no value in evaluating the performance of the model as defined here. Firstly, the model will have 100% as the number of neighbours considered is one and the full dataset is used for training. Secondly, there's no desire to make predictions so over-fitting is inconsequential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Shapley values to identify the impact of the presence of an ingredient on the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set summary of data for baseline and sample instances to examine shap values of\n",
    "with warnings.catch_warnings():  # silence warnings due to deprecations of sklearn components not resolved in SHAP\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    ingredients_cluster = shap.kmeans(ingredients, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate shap values\n",
    "explainer = shap.KernelExplainer(\n",
    "    model=lambda x: knn.predict(x), data=ingredients_cluster\n",
    ")\n",
    "shap_values = pd.DataFrame(\n",
    "    data=explainer.shap_values(X=ingredients),\n",
    "    columns=ingredients.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the impact of not having an ingredient vs having it\n",
    "\n",
    "# initialise series object\n",
    "rating_impact = pd.Series(dtype=float)\n",
    "\n",
    "# loop over each ingredient\n",
    "for (ingredient, presence), (ingredient_comp, shap) in zip(\n",
    "    ingredients.copy().items(), shap_values.copy().items()\n",
    "):\n",
    "\n",
    "    # check ingredient names match\n",
    "    assert ingredient == ingredient_comp\n",
    "\n",
    "    # rename series prior to concatenation\n",
    "    presence.name = \"presence\"\n",
    "    shap.name = \"rating_impact\"\n",
    "\n",
    "    # calculate the average impact of having vs not having the ingredient\n",
    "    impact = (\n",
    "        pd.concat([presence, shap], axis=1).groupby(\"presence\").mean()[\"rating_impact\"]\n",
    "    )\n",
    "\n",
    "    # store the improvement in average rating due to the presence of the ingredient\n",
    "    rating_impact[ingredient] = impact[True] - impact[False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse impact of ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify most significant ingredients\n",
    "\n",
    "# set number of ingredients\n",
    "n = 25\n",
    "\n",
    "# ingredients to include\n",
    "top = (\n",
    "    rating_impact.nlargest(n)\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"ingredient\", 0: \"rating_impact\"})\n",
    ")\n",
    "top.columns = pd.MultiIndex.from_tuples(\n",
    "    ((\"include\", item) for item in top.columns), names=[None] + top.columns.names\n",
    ")\n",
    "\n",
    "# ingredients to avoid\n",
    "bottom = (\n",
    "    rating_impact.nsmallest(n)\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"ingredient\", 0: \"rating_impact\"})\n",
    ")\n",
    "bottom.columns = pd.MultiIndex.from_tuples(\n",
    "    ((\"exclude\", item) for item in bottom.columns), names=[None] + bottom.columns.names\n",
    ")\n",
    "\n",
    "# display results\n",
    "pd.concat([top, bottom], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set of ingredient allows product developers to flavours to be consider or avoided:\n",
    "- ✅ Reese's Peanut Butter Cups\n",
    "- ✅ Banana\n",
    "- ✅ Mint\n",
    "- ✅ Pineapple\n",
    "- ✅ Pistachio\n",
    "- ✅ Toffee\n",
    "- ✅ Mango\n",
    "- ✅ Apple\n",
    "- ❌ Peaches\n",
    "- ❌ Green tea\n",
    "- ❌ Raisins\n",
    "- ❌ Plum\n",
    "- ❌ Rum\n",
    "\n",
    "It also highlights the importance of using higher quality variants of particular flavours\n",
    "- ✅ Ground vanilla beans vs ❌ Vanilla extract\n",
    "- ✅ Coffee vs ❌ Coffee extract\n",
    "- ✅ Chocolate vs ❌ Cocoa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d203e968258da72cd4118352c26f273da2f4e5303f1bd70f028c0e2c03554780"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
